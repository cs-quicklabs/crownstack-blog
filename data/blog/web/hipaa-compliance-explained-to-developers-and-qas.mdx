---
title: "HIPAA Beyond Theory: What Companies Should Know, Developers Must Implement and QA Needs to Test"
date: '2025-09-16'
tags: ['compliance', 'hipaa']
draft: false
summary: "In this blog we will deep dive into HIPAA - explaining what it is, breaking down its rules, mapping each rule to what developers must implement, and outlining what QA needs to test to ensure full compliance."
layout: PostSimple
authors: ['varun-kumar']
---

# What is HIPAA and PHI?

HIPAA stands for **Health Insurance Portability and Accountability Act**, is a U.S. law that sets rules for keeping patient health information private and secure. The main goal of HIPAA is to make sure that sensitive medical details of patients are not shared or exposed without patients' permission. This sensitive information is called **PHI (Protected Health Information)**, and it includes anything that can identify a patient along with their health conditions - like names, addresses, medical records, test results, or even things like phone numbers and insurance details.

In simple terms, HIPAA makes sure that when a software or people working on that software handle any patient's data, it is kept safe, private, and only used for the right reasons.



# What patient information is considered under PHI (PHI identifiers)?

PHI (Protected Health Information) is any information that:

1. Identifies an individual (or can be used to identify an individual)
2. Relates to their health condition, healthcare, or payment for healthcare


HIPAA lists **18 identifiers** that make health data "individually identifiable". If any of these are present with health-related info, it becomes PHI:

* Name
* Address (street, city, county, ZIP, etc.)
* Dates (birth date, admission/discharge date, death date, exact age >89)
* Telephone numbers
* Fax numbers
* Email addresses
* Social Security Number (SSN)
* Medical record number
* Health plan beneficiary number
* Account numbers
* Certificate/license numbers
* Vehicle identifiers (license plate, VIN)
* Device identifiers/serial numbers (e.g. implanted medical device ID)
* Web URLs
* IP addresses
* Biometric identifiers (fingerprints, voiceprints, retinal scans)
* Full-face photos and comparable images
* Any other unique identifying number, code, or characteristic



# What type of software needs to be HIPAA compliant?

As a general thumb rule, any software that **creates, receives, maintains, or transmits PHI** must be HIPAA compliant. This includes:

* **Electronic Health Record (EHR) / EMR Systems** - Used by hospitals, clinics, and doctors to manage patient records
* **Telemedicine & Telehealth Apps** - Video consultation platforms, or chat-based health services
* **Medical Billing Management Software** - Systems handling insurance claims, billing, and patient data
* **Patient Portals** - Web or mobile apps where patients can view test results, prescriptions, or communicate with doctors
* **Healthcare CRM Systems** - Customer/patient management tools for healthcare providers
* **Mobile Health Apps (mHealth)** - Apps tracking health vitals (like heart rate, glucose, or blood pressure) if they share or store PHI with a provider or insurer
* **Cloud Storage & SaaS Platforms for Healthcare** - Any cloud software where PHI is stored, transmitted, or backed up (AWS, GCP, Azure all offer HIPAA-compliant services)

If no PHI is involved (e.g., a general fitness tracker storing steps locally), HIPAA does not apply.



# Why implementing HIPAA is crucial for a software?

If a software (and indirectly the parent company owning that software) that handles Protected Health Information (PHI) does not follow HIPAA compliance, the consequences can be serious - legally, financially, and reputationally.


## Civil Penalties (Fines) imposed by US Government

HIPAA violations can lead to civil monetary penalties from the **U.S. Department of Health and Human Services (HHS) Office for Civil Rights (OCR)**.

The fine amount depends on level of negligence:

| **Violation Type**                            | **Fine (per violation)** |
| --------------------------------------------- | ------------------------ |
| Did not know (unintentional, no way to avoid) | $100 - $50,000         |
| Reasonable cause (knew or should have known)  | $1,000 - $50,000       |
| Willful neglect (corrected in time)           | $10,000 - $50,000      |
| Willful neglect (not corrected)               | $50,000                 |


## Criminal Penalties

If violations are found intentional or malicious, the **Department of Justice (DOJ)** can prosecute:

| **Violation Type**                            | **Fine (per violation)** |
| --------------------------------------------- | ------------------------ |
| Knowingly obtaining or disclosing PHI | Up to $50,000 fine + 1 year in prison |
| Intentionally obtaining something (like money, property, or information) by lying, deceiving, or misrepresenting facts  | Up to $100,000 fine + 5 years in prison |
| Offenses for personal gain, malicious harm, or commercial advantage | up to $250,000 fine + 10 years in prison |

## Lawsuits & Liability


If a patient's PHI is exposed, they can take legal action under state laws such as negligence or invasion of privacy. Business associates - like software vendors - may also be held liable if their actions lead to a breach.


## Reputation Damage

Public trust is critical in healthcare. A HIPAA violation can damage credibility and cause loss of business. Customers of the software (hospitals, clinics, insurers) may cancel contracts with vendors that are non-compliant.


## Operational Impact

Software that is not HIPAA-compliant cannot legally be used by hospitals, clinics, or insurers (covered entities). Non-compliance may force you to rebuild parts of the system, delay launches, or lose market access.

Hence taking HIPAA seriously and ensuring compliance is crucial for any software handling PHI.



# What PHI data can software legally reveal and to whom?

Under HIPAA's Privacy Rule, PHI can only be used or disclosed for permitted purposes (treatment, payment, healthcare operations, public health, etc.) without patient authorization. The Privacy Rule imposes a **"minimum necessary"** standard: PHI data use and disclosures must be limited to the least amount of PHI needed for the purpose.

Here's a breakdown of who can see PHI and under what conditions:

| **Who Can Access PHI**                     | **Conditions/Reasons**                                      |
| ------------------------------------------ | ----------------------------------------------------------- |
| **Healthcare Providers**                   | For treatment, payment, and healthcare operations           |
| **Health Insurers**                | For payment and healthcare operations                       |
| **Business Associates**                    | If they sign a Business Associate Agreement (BAA)          |
| **Patients**                               | They have the right to access their own PHI                  |
| **Family Members & Friends**               | If the patient agrees or in emergencies                     |
| **Public Health Authorities**              | For public health activities (e.g., disease reporting)        |
| **Law Enforcement**                        | For law enforcement purposes (e.g., court orders)          |
| **Researchers**                            | If approved by an Institutional Review Board (IRB)          |
| **Government Agencies**                    | For audits, investigations, or inspections                  |



# What are patients' rights under HIPAA?

HIPAA isn't just about rules for healthcare providers. It also gives patients important rights, including:

* **Access their medical records** - View or get a copy of their health information
* **Request corrections** - Ask to fix any errors or missing information in their records
* **Receive a Notice of Privacy Practices** - Learn how their health information is used and protected
* **Get a record of disclosures** - See who their information has been shared with
* **Request restrictions** - Ask to limit how their information is used or shared
* **Request confidential communications** - Choose how or where they are contacted for privacy
* **File complaints** - Report if they believe their privacy rights were violated


Now that we have a foundational understanding of HIPAA, PHI, the importance of compliance, and what legalities are involved if HIPAA is not followed properly. Now let's move ahead and deep dive into how to actually implementation HIPAA rules and what testing aspects of HIPAA compliance QA teams need to focus on before giving their final sign-off.



# Guidelines to adapt your software for HIPAA

To begin with, let's categorize all the actions and steps HIPAA expects from a software into 3 main buckets:

1. **Administrative Safeguards** - Policies and procedures to ensure PHI is protected and guiding how the workforce handles it securely
2. **Physical Safeguards** - Steps and rules that keep computers, equipment, and buildings safe from damage, accidents, or unauthorized access that can compromise PHI
3. **Technical Safeguards** - software changes, building secure systems, and access controls that protect electronic PHI

Now let's deep dive into each of these buckets, understand the specific HIPAA rules under each buckets.

## 1. Administrative Safeguards

Administrative Safeguards are organization-wide policies and procedures to manage PHI security. Key requirements include risk management, workforce policies, and oversight:

1. **Risk Analysis & Management**: Identify all possible risks to patient data (like hackers, software bugs, or system failures), figure out how likely they are, and take steps to reduce them.
2. **Security Management**: Assign someone responsible for HIPAA security, create clear written rules (like who can access data and what to do if there's a breach), and enforce consequences for breaking those rules.
3. **Access Control**: Only allow staff to see the data they need for their job. For example, billing staff see billing info, doctors see clinical info.
4. **Workforce Training**: Regularly teach everyone (developers, QA, admins) about HIPAA rules and safe ways to handle patient data.
5. **Incident Response**: Have a clear plan for detecting, reporting, and handling data breaches or security problems, including who to contact and what steps to take.
6. **Contingency Planning**: Keep backups, disaster recovery plans, and emergency procedures to restore patient data if it's lost. Data must be fully recoverable.
7. **Evaluation & Documentation**: Review and update security policies regularly. Keep records of all policies, training, risk assessments, and compliance activities.
8. **Business Associate Agreements (BAAs)**: Any vendor or partner handling patient data must sign a HIPAA agreement. If your software uses a cloud provider (like AWS) to store PHI, ensure there's a BAA in place.
9. **Developer Actions**: Help with compliance by participating in risk assessments, reviewing code for vulnerabilities, implementing security policies in the software (like password rules or session timeouts), checking third-party services for HIPAA compliance, encrypting devices that handle PHI, and documenting design and security decisions.
10. **QA Testing**: Verify that risk assessments exist and mitigation plans are tracked. Test backups by simulating data loss to make sure PHI can be restored. Check that all team members have completed HIPAA training. Confirm that vendor agreements and policies are in place. Test the incident response plan by running mock breach scenarios to ensure each step works correctly.


## 2. Physical Safeguards

Physical Safeguards protect the actual hardware and facilities where PHI is stored or accessed. Key requirements include:

1. **Facility Access Controls**: Limit who can physically enter areas with patient data (like server rooms or offices) using locks, ID badges, keycards, or biometrics. For cloud setups, pick data centers with strong physical security.
2. **Workstation Security**: Set rules for using computers and devices - use privacy screens, lock screens automatically after inactivity, and disable risky features like USB ports if needed.
3. **Device & Media Controls**: Keep a list of devices (laptops, phones, USB drives) that access patient data. Track removable media, and securely erase or destroy it before reuse. Follow standard guidelines for safely wiping data.
4. **Developer Actions**:
    1. Use HIPAA-compliant servers or cloud setups
    2. Encrypt all devices that handle patient data
    3. Minimize local storage of sensitive data in apps
    4. Add remote wipe and auto-lock features for mobile devices
    5. Make sure temporary files are securely deleted when no longer needed
5. **QA Checks**:
    1. Check that physical safeguards are in place
    2. Ensure no patient data is stored in plaintext in logs or temporary files
    3. Test mobile apps: store sample patient data, then wipe it and confirm it cannot be recovered
    4. Verify apps lock automatically after inactivity and require re-login
    5. Review data-center or hosting provider compliance documents for physical security


## 3. Technical Safeguards

Technical Safeguards are technology-based controls within the software/system. HIPAA divides controls into 5 key areas:

### 3.1. Access Control

HIPAA requires software to make it mandatory to enforce various technical policies and procedures to let only authorized persons or software access ePHI. Listing down what needs to be implemented by developers to ensure access control is safeguarded:


#### 3.1.1. **User Identity & Roles**:

##### 3.1.1.1. Assign every user a unique account/ID:

| Check to perform | Developer Actions | QA Checks |
| ---------------- | ----------------- | --------- |
| Unique Username/ID | Generate unique IDs (UUIDs or auto-increment IDs) for each user in your database | Verify that the user_id field (or equivalent) is unique in the database schema |
| Avoiding duplication | Enforce unique usernames or email addresses at registration | Try creating two accounts with the same email/username → it should fail with an error |
| Rejecting generic login accounts | Don't allow shared or generic usernames like "admin" or "doctor" | Do negative testing by attempting to create accounts with generic usernames → it should be rejected |


##### 3.1.1.2. Use role-based (RBAC) or attribute-based access control to restrict PHI by job function or attributes:

| Check to perform | Developer Actions | QA Checks |
| ---------------- | ----------------- | --------- |
| Role and Attribute Definitions | Define clear roles (e.g., Doctor, Nurse, Biller, Admin) and attributes (e.g., department, specialty, clearance level). Ensure that eEach role/attribute must have **minimum necessary access** to PHI. | Create test users for each role/attribute. Verify each user can only access what their role allows. Example: A Biller should fail when trying to open clinical notes. |
| Access Enforcement in Code | Implement middleware or authorization checks to enforce RBAC/ABAC before accessing PHI endpoints. | Try unauthorized actions with restricted roles and confirm access is denied. Ensure error messages don't leak sensitive info (e.g., "Access Denied" instead of "Record exists but you can't view it"). |
| Least Privilege Principle | Default new accounts to the lowest privilege until explicitly assigned. | Attempt to modify tokens, cookies, or API calls to impersonate higher roles. Verify system blocks all privilege escalation attempts. |
| Audit Logging | Log all access attempts, including denied ones, with user ID + role + resource requested. | Perform access attempts (both allowed and denied). Check audit logs to confirm user ID, role, and access results are recorded properly. |


##### 3.1.1.3. Include "**break-glass**" or emergency roles so designated staff can retrieve PHI during emergencies:

| Check to perform | Developer Actions | QA Checks |
| ---------------- | ----------------- | --------- |
| Emergency Role Design | Define a special break-glass role that overrides normal access restrictions. Access should be **temporary** and **time-limited**. | Test that emergency roles can indeed bypass normal restrictions and access PHI. Confirm normal roles cannot access restricted data without break-glass. |
| Strict Access Controls | Only specific users (e.g., emergency physicians, compliance officers) can be assigned this role. Require strong authentication (MFA, secure approval flow) before activation. | Attempt break-glass activation as unauthorized users → system must deny. Confirm only designated staff can activate emergency role. |
| Audit Logging | Log every emergency access attempt with Who, When, What PHI and Why | Trigger emergency access and check logs: verify all details (who, when, what data, why). Ensure failed/denied break-glass attempts are also logged. Try to activate without giving a reason → system should block or require justification. |
| Automatic Revocation | Emergency access should auto-expire after a set period (e.g., 1 hour). System should revert user to their normal role. | Activate break-glass, wait past time limit, then confirm access is revoked automatically. Verify system doesn’t let a user keep emergency access indefinitely. |
| Alerting | Trigger real-time alerts (email, dashboard, SIEM integration) when break-glass access is used. | Trigger break-glass access and check that alerts/notifications were sent. |
